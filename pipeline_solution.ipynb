{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614b425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from annoy import AnnoyIndex\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import csv\n",
    "from bert_score import score\n",
    "import clickhouse_driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0139fdbd",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "746085de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= pd.read_csv(\"data.csv\") \n",
    "test_data[\"answer\"] = test_data[\"answer\"].str.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7595e939",
   "metadata": {},
   "source": [
    "# Был взят небольшой эмбеддер на базе BERTа, способный работать с русским языком https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
    "## При возможности, можно взять эмбеддер побольше - https://huggingface.co/intfloat/e5-mistral-7b-instruct, но мы сочли, что нам хватит и небольшого, лучше взять модель 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18f300b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-14 12:40:27,668] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 12:40:28.222567: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
    "model = model.to('cuda')\n",
    "embeddings = model.encode(test_data['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2522a4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(611, 768)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336bfc14",
   "metadata": {},
   "source": [
    "# Пайплайн PCA для понижения размерности, 768 - слишком много, 300 - оптимально, если система все равно нагружается сильно, то можно попробовать понизить ещё до ~100-200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c9cf1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = Pipeline(steps=[\n",
    "    ('mean', StandardScaler(with_mean=True, with_std=False)),\n",
    "    ('pca', PCA(n_components=300, random_state=42)),\n",
    "    ('std', StandardScaler(with_mean=True, with_std=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35bf03cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(611, 300)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(embeddings)\n",
    "text_vectors = pca.transform(embeddings)\n",
    "text_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa200fbe",
   "metadata": {},
   "source": [
    "# Clickhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84485013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание таблицы\n",
    "import clickhouse_driver\n",
    "\n",
    "client = clickhouse_driver.Client(host='localhost')\n",
    "\n",
    "# client.execute(\"DROP TABLE embeddings\") # Если нужно удалить существующую таблицу\n",
    "client.execute(\"\"\"\n",
    "CREATE TABLE embeddings (\n",
    "    id UInt32,\n",
    "    embedding Array(Float32),\n",
    "    link String\n",
    ")\n",
    "ENGINE = MergeTree\n",
    "PRIMARY KEY (id)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1218576f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "611"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка существующей таблицы\n",
    "len(client.execute(\"SELECT * FROM embeddings\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6da8fe5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clickhouse_connect.driver.summary.QuerySummary at 0x7fb5f0440310>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Заполнение таблицы\n",
    "import clickhouse_connect\n",
    "\n",
    "client = clickhouse_connect.get_client()\n",
    "\n",
    "embeddings = text_vectors.tolist()\n",
    "links = test_data['link'].tolist()\n",
    "ids = list(range(len(text_vectors)))\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    row = [ids[i], embeddings[i], links[i]]\n",
    "    data.append(row)\n",
    "\n",
    "client.insert('embeddings', data, column_names=['id', 'embedding', 'link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11b0a16",
   "metadata": {},
   "source": [
    "# Загружаем языковую модель и токенизатор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de80e89",
   "metadata": {},
   "source": [
    "## Была выбрана mistral instruct. Во-первых, модель является оптимальной по количеству парамтров и качеству генерации, так, Mistral 7B побеждает Llama v2 13B на большинстве бенчмарков.      \n",
    "## Во-вторых, у модели достаточно большой размер контекста - 8К токенов, что позволяет помещать в контекст параграфы большого размера и не терять важную информацию при нарезке документов.      \n",
    "## В-третьих, instuct версия дополнительно обучена на аннотированном (размеченном) вручную инструкционном датасете (каждая инструкция - это пара \"вопрос\" - \"правильный с точки зрения человека ответ\", а обычные, не иструкционные модели, до этой стадии дообучения не дошли, а просто обучены предсказывать следующее слово на очень большом, но неразмеченном текстовом корпусе).   \n",
    "## Кроме того, модель неплохо работает с русским языком"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16884278",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_dirname = '../nsu-ai/team_code/models/llm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840cc35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если у вас модель не загружена локально, то\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "# https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2, если недоступна последняя версия transformers, то можно использовать v0.1 - https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\n",
    "# если версии библиотек не самые новые, то v0.1 может работать быстрее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cbc77499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7090022ddecb44c6b8c090f423583ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_model = AutoModelForCausalLM.from_pretrained(llm_dirname, torch_dtype=torch.float16, device_map={\"\":0}) # device_map требует установки Accelerate\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1e602",
   "metadata": {},
   "source": [
    "# Получение индекса наиболее подходящего документа по запросу (можно переделать на несколько подходящих индексов (размер контекста позволяет)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50abb94b",
   "metadata": {},
   "source": [
    "## Можно возвращать несколько документов, добавлять несколько в контекст (если взять чанки меньшего размера) Также можно добавить небольшую модель, которая без Retrieval будет генерировать ответ, на основе него дополнительно ранжировать топ-N документов по близости эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5666ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_document_idx(query: list) -> int:\n",
    "    embedding = model.encode(query)\n",
    "    pca_embedding = pca.transform(embedding)\n",
    "    pca_embedding = np.squeeze(pca_embedding)\n",
    "    query_vector = pca_embedding.tolist()\n",
    "    results = client.execute(\"\"\"\n",
    "    SELECT id, embedding, link\n",
    "    FROM embeddings\n",
    "    ORDER BY L2Distance(embedding, {}) ASC\n",
    "    LIMIT 1\n",
    "    \"\"\".format(query_vector))\n",
    "    \n",
    "    return results[0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a0ade1",
   "metadata": {},
   "source": [
    "# Генерация ответа моделью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eb9061cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(query: str, model, tokenizer, documents=test_data, with_link=False) -> str:\n",
    "    device = \"cuda:0\"\n",
    "    document_idx = get_closest_document_idx([query])\n",
    "    found_text = documents['answer'][document_idx]\n",
    "    prompt_template = f\"\"\"[INST]Ты русскоязычный помощник банка россии, который отвечает на вопросы. Ты знаешь что: {found_text} Вопрос: {query} Отвечай только то, в чем уверен. [/INST]\n",
    "    \"\"\"\n",
    "    prompt = prompt_template.format(query=query)\n",
    "\n",
    "    encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "    model_inputs = encodeds.to(device)\n",
    "\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=500)\n",
    "    decoded = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    if with_link:\n",
    "        return (decoded[0] + ' Ответ основан на ' + documents['link'][document_idx], len(prompt))\n",
    "    return (decoded[0], len(prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b93ec",
   "metadata": {},
   "source": [
    "# Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "896ee84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Я уверен, что курс рубля определяется соотношением спроса на иностранную валюту и ее предложения на валютном рынке. Причинами изменения курса рубля могут быть любые факторы, влекущие изменение соотношения между спросом на иностранную валюту и ее предложением. В отдельные периоды могут преобладать факторы в пользу ослабления рубля, несмотря на одновременное действие других факторов в сторону его укрепления. Например, в конце 2013 — начале 2014 года интерес международных инвесторов к активам стран с формирующимися рынками, в том числе к российским активам, заметно снизился. Это оказалось более значимым, чем высокие цены на нефть в данный период, что привело к ослаблению рубля. Ответ основан на https://www.cbr.ru/dkp/faq/'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, l = get_completion(query='Что такое курс рубля и почему он меняется?', model=llm_model, tokenizer=tokenizer, documents=test_data, with_link=True)\n",
    "result[l:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b2283",
   "metadata": {},
   "source": [
    "# Подсчет BERT F1 Score - https://github.com/Tiiiger/bert_score/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf08dd",
   "metadata": {},
   "source": [
    "## первые 333 элемента из раздела вопрос-ответ, поэтому на вопросах оттуда можно проверить работу системы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fe11595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = test_data['answer'][:333].values.tolist()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af225e49",
   "metadata": {},
   "source": [
    "## Для простоты возьмем первые 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd17a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for question in test_data['text'][:150]:\n",
    "    result, l = get_completion(query=question, model=llm_model, tokenizer=tokenizer, documents=test_data)\n",
    "    answers.append(' '.join(result[l+1:].split()).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "303f64cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa4967325f44249804112ab5c37043b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bc82344407404dbb2fea400700eecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 7.54 seconds, 19.88 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "P, R, F1 = score(answers[:150], refs[:150], lang='en', verbose=True) # Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d5b59918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На 150 вопросах из раздела вопрос-ответ, усредненный BERT F1 score:  tensor(0.8951)\n"
     ]
    }
   ],
   "source": [
    "print('На 150 вопросах из раздела вопрос-ответ, усредненный BERT F1 score: ', F1.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
